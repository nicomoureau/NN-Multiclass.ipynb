{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.activations import relu,linear\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, load_img"
      ],
      "metadata": {
        "id": "tFh_MghEebyg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ds = tfds.load('mnist', split='train', as_supervised=True, shuffle_files=True)\n",
        "\n",
        "#Load the training data\n",
        "train_ds, test_ds = tfds.load('mnist', split=['train', 'test[:30%]'],as_supervised=True, shuffle_files=True)\n",
        "\n",
        "\n",
        "#load the image\n",
        "image_path = '../model7.png'\n",
        "\n",
        "image = load_img(image_path, color_mode='grayscale', target_size=(28, 28))\n",
        "\n",
        "#process the image\n",
        "image = img_to_array(image)  # Convert the image to an array\n",
        "image = image.reshape(1,28, 28, 1)  # Reshape it to (1, 28, 28, 1)\n",
        "image = image.astype('float32') / 255.0  # Normalize pixel values\n",
        "\n",
        "# Preprocess the dataset: normalize and convert data type\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize and convert to float32\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "train_ds = train_ds.map(preprocess)\n",
        "test_ds = test_ds.map(preprocess)\n",
        "\n",
        "# Batch and prefetch\n",
        "\n",
        "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "#display the input image\n",
        "\n",
        "img = mpimg.imread(image_path)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#displain the\n",
        "\n",
        "# ds_sample = train_ds.take(1)\n",
        "\n",
        "# # Plot the images in a 3x3 grid\n",
        "# fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "# fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "\n",
        "# for i, (image, label) in enumerate(ds_sample):\n",
        "#     ax = axes[i // 3, i % 3]\n",
        "#     # Ensure the image is correctly shaped for display\n",
        "#     img_2d = image.numpy().squeeze()  # Remove extraneous dimensions\n",
        "#     if img_2d.ndim == 2:  # Check if the image is 2D as expected\n",
        "#         ax.imshow(img_2d, cmap='gray')\n",
        "#         ax.set_title(f'Label: {label.numpy()}')\n",
        "#         ax.axis('off')\n",
        "#     else:\n",
        "#         print(f\"Unexpected image shape: {img_2d.shape}\")\n",
        "\n",
        "# for images, labels in train_ds.take(100):  # Taking one batch\n",
        "#     plt.figure(figsize=(10, 10))\n",
        "#     for i in range(9):  # Assuming you want to display 9 images\n",
        "#         ax = plt.subplot(3, 3, i + 1)\n",
        "#         img = images[i].numpy().astype(\"uint8\")  # Access the i-th image in the batch and convert to uint8\n",
        "#         plt.imshow(img, cmap='gray')\n",
        "#         plt.title(int(labels[i]))\n",
        "#         plt.axis(\"off\")\n",
        "\n",
        "\n",
        "\n",
        "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
        "        tf.keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "        #tf.keras.layers.Dense(80, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "        tf.keras.layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "        tf.keras.layers.Dense(10, activation=\"linear\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "        #tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    #loss=SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=test_ds\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "test_loss_train = model.evaluate(train_ds)\n",
        "print(f\"Test Loss Train: {test_loss_train}\")\n",
        "\n",
        "test_loss_test = model.evaluate(test_ds)\n",
        "print(f\"Test Loss Test: {test_loss_test}\")\n",
        "\n",
        "prediction = model.predict(image)\n",
        "\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "# Interpret the output\n",
        "predicted_digit = np.argmax(prediction)\n",
        "print(f\"Predicted digit: {predicted_digit}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PZsOJDyKe9LU",
        "outputId": "000009ed-6e05-4a29-97e8-23f623c8c137"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 13s 6ms/step - loss: 0.5784 - accuracy: 0.8981 - val_loss: 0.4681 - val_accuracy: 0.9217\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4928 - accuracy: 0.9153 - val_loss: 0.4385 - val_accuracy: 0.9290\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4701 - accuracy: 0.9184 - val_loss: 0.4424 - val_accuracy: 0.9263\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4683 - accuracy: 0.9179 - val_loss: 0.4280 - val_accuracy: 0.9267\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4560 - accuracy: 0.9212 - val_loss: 0.4096 - val_accuracy: 0.9327\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4518 - accuracy: 0.9212 - val_loss: 0.4254 - val_accuracy: 0.9293\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4512 - accuracy: 0.9208 - val_loss: 0.4016 - val_accuracy: 0.9387\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4498 - accuracy: 0.9216 - val_loss: 0.4580 - val_accuracy: 0.9173\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4508 - accuracy: 0.9208 - val_loss: 0.4484 - val_accuracy: 0.9257\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4445 - accuracy: 0.9235 - val_loss: 0.3921 - val_accuracy: 0.9360\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84060 (328.36 KB)\n",
            "Trainable params: 84060 (328.36 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3888 - accuracy: 0.9424\n",
            "Test Loss Train: [0.38881754875183105, 0.9424333572387695]\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 0.3921 - accuracy: 0.9360\n",
            "Test Loss Test: [0.3920730650424957, 0.9359999895095825]\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "[[-2.2793367  -1.7641242   0.62401795  1.5443785  -1.5612129  -0.18479234\n",
            "  -4.564786    4.157487   -0.40975523  2.6315532 ]]\n",
            "Predicted digit: 7\n"
          ]
        }
      ]
    }
  ]
}